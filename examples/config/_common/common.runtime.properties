# Extensions (no deep storage model is listed - using local fs for deep storage - not recommended for production)
druid.extensions.coordinates=["io.druid.extensions:druid-examples","io.druid.extensions:druid-kafka-eight","io.druid.extensions:mysql-metadata-storage","io.druid.extensions:druid-hdfs-storage"]

# Request logging, monitoring, and metrics
#druid.request.logging.type=emitter
#druid.request.logging.feed=druid_requests

#druid.monitoring.monitors=["com.metamx.metrics.JvmMonitor"]

# Metadata Storage (mysql)
druid.metadata.storage.type=mysql
druid.metadata.storage.connector.connectURI=jdbc\:mysql\://10.1.81.73\:3306/druid
druid.metadata.storage.connector.useValidationQuery=true
druid.metadata.storage.connector.createTables=true
druid.metadata.storage.connector.user=bi_druid
druid.metadata.storage.connector.password=AD6^>PuwBEib14

# Deep storage (local filesystem for examples - don't use this in production)
druid.storage.type=hdfs
druid.storage.storageDirectory=/data1/druid/warehouse

# Query Cache (we use a simple 10mb heap-based local cache on the broker)
#druid.cache.type=local
#druid.cache.sizeInBytes=10000000

# Indexing service discovery
druid.selectors.indexing.serviceName=overlord

# Monitoring (disabled for examples, if you enable SysMonitor, make sure to include sigar jar in your cp)
# druid.monitoring.monitors=["com.metamx.metrics.SysMonitor","com.metamx.metrics.JvmMonitor"]

# Metrics logging (disabled for examples - change this to logging or http in production)
druid.emitter=noop
#druid.emitter=http

#maven 本地仓库
druid.extensions.localRepository=/data2/druid/.m2/repository

#zookeeper path
druid.zk.paths.base=/druid
druid.zk.service.host=10.1.80.249,10.1.80.250,10.1.80.251
druid.zk.service.sessionTimeoutMs=30000
#Znodes 压缩
druid.curator.compress=true
#服务竞选地址
druid.discovery.curator.path=/druid/discovery

#log
#查询request日志记录方式，支持noop,file,emitter
druid.request.logging.type=noop
#file request logging dir
#druid.request.logging.dir
#emitter request logging
#druid.request.logging.feed=
